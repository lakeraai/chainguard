# Welcome to Lakera ChainGuard


This site contains the project documentation for the [**lakera_chainguard**](https://github.com/lakeraai/lakera_langchain_integration) package. The package allows you to secure Large Language Model (LLM) applications and agents built with [LangChain](https://www.langchain.com/) from [prompt injection and jailbreaks](https://platform.lakera.ai/docs/prompt_injection) (and [other risks](https://platform.lakera.ai/docs/api)) with [Lakera Guard](https://www.lakera.ai/).


## Acknowledgements
Thanks to all the people who have contributed to this project, and to the people who have inspired us to create it. In particular, thanks to the team at Lakera AI for their positive feedback and support.
